{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ec2ccd",
   "metadata": {},
   "source": [
    "# Access to Data and Model\n",
    "\n",
    "Before you continue please download the data and the model from: https://figshare.com/s/3cb512c318285fba5051. Unpack it and move the _model_ to __models__ and the _data_ to __data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7c457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from fim.models.hawkes import FIMHawkes\n",
    "from utils import load_data_from_dir, prepare_batch_for_model, plot_intensity_comparison, _move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15caf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_checkpoint = Path(\"../models/\")\n",
    "dataset_dir = Path(\"../data/\")\n",
    "\n",
    "print(f\"Loading model from: {model_checkpoint}\")\n",
    "print(f\"Loading dataset from: {dataset_dir}\")\n",
    "\n",
    "# Load model with proper weight loading (bypasses transformers issues)\n",
    "model = FIMHawkes.load_model(model_checkpoint)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "data = load_data_from_dir(dataset_dir)\n",
    "if not data:\n",
    "    raise ValueError(\"No data loaded. Exiting.\")\n",
    "\n",
    "\n",
    "print(f\"Loaded data with keys: {list(data.keys())}\")\n",
    "\n",
    "# Use the specified sample index\n",
    "sample_idx = 10\n",
    "path_idx = 0\n",
    "\n",
    "# Validate sample index\n",
    "sample_count = None\n",
    "for key, value in data.items():\n",
    "    if torch.is_tensor(value):\n",
    "        sample_count = value.shape[0]\n",
    "        break\n",
    "\n",
    "if sample_count is not None and sample_idx >= sample_count:\n",
    "    print(f\"Warning: sample_idx {sample_idx} >= number of samples {sample_count}. Using sample 0.\")\n",
    "    sample_idx = 0\n",
    "\n",
    "print(f\"Using sample index: {sample_idx}\")\n",
    "\n",
    "single_sample_data = {}\n",
    "for key, value in data.items():\n",
    "    if torch.is_tensor(value):\n",
    "        single_sample_data[key] = value[sample_idx]\n",
    "    else:\n",
    "        # Handle non-tensor data if necessary, e.g., lists of tensors\n",
    "        single_sample_data[key] = value[sample_idx]\n",
    "\n",
    "try:\n",
    "    model_data = prepare_batch_for_model(single_sample_data, path_idx, num_points_between_events=10)\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error preparing batch: {e}\")\n",
    "\n",
    "print(\"Model input shapes:\")\n",
    "for key, value in model_data.items():\n",
    "    if torch.is_tensor(value):\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "print(f\"Using path index: {path_idx}\")\n",
    "\n",
    "# Ensure model inputs are on the same device as the model\n",
    "model_data = _move_to_device(model_data, device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = model(model_data)\n",
    "\n",
    "print(f\"Model output keys: {list(model_output.keys())}\")\n",
    "\n",
    "# save_path = f\"intensity_comparison_sample_{sample_idx}_path_{path_idx}.png\"\n",
    "plot_intensity_comparison(model_output, model_data, path_idx=path_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf4aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
